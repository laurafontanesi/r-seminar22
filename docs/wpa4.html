<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Data wrangling</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">R seminar</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Syllabus</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fas fa-display"></span>
     
    WPAs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="wpa1.html">WPA 1</a>
    </li>
    <li>
      <a href="wpa2.html">WPA 2</a>
    </li>
    <li>
      <a href="wpa3.html">WPA 3</a>
    </li>
    <li>
      <a href="wpa4.html">WPA 4</a>
    </li>
    <li>
      <a href="wpa5.html">WPA 5</a>
    </li>
    <li>
      <a href="wpa6.html">WPA 6</a>
    </li>
    <li>
      <a href="wpa7.html">WPA 7</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fas fa-display-arrow-down"></span>
     
    Solutions
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="wpa1_solutions.html">WPA 1</a>
    </li>
    <li>
      <a href="wpa2_solutions.html">WPA 2</a>
    </li>
    <li>
      <a href="wpa3_solutions.html">WPA 3</a>
    </li>
    <li>
      <a href="wpa4_solutions.html">WPA 4</a>
    </li>
    <li>
      <a href="wpa5_solutions.html">WPA 5</a>
    </li>
    <li>
      <a href="wpa6_solutions.html">WPA 6</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Data wrangling</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#load-data-in-r">Load data in R</a></li>
<li><a href="#what-is-data-wrangling">1. What is data wrangling?</a></li>
<li><a href="#functions-to-know-and-some-examples">2. Functions to know and some examples</a>
<ul>
<li><a href="#ways-to-see-the-data-glimpse-sort-head-and-tail">Ways to “see” the data: Glimpse, sort, head, and tail</a></li>
<li><a href="#select-or-drop-specific-columns-and-rows-indexing">Select or drop specific columns and rows (indexing)</a></li>
<li><a href="#change-values-or-value-types-indexing-and-reassigning">Change values or value types (indexing and reassigning)</a></li>
<li><a href="#compute-summary-statistics">Compute summary statistics</a></li>
<li><a href="#split-character-columns">Split character columns</a></li>
<li><a href="#merge-character-columns">Merge character columns</a></li>
</ul></li>
<li><a href="#pipes">3. Pipes</a></li>
<li><a href="#join-dataframes">4. Join dataframes</a></li>
<li><a href="#now-its-your-turn">6. Now it’s your turn</a>
<ul>
<li><a href="#submit-your-assignment">Submit your assignment</a></li>
</ul></li>
</ul>
</div>

<p>Open RStudio.</p>
<p>Open a new R script in R and <strong>save it as</strong> <code>wpa_4_LastFirst.R</code> (where Last and First is your last and first name).</p>
<p>Careful about: capitalizing, last and first name order, and using <code>_</code> instead of <code>-</code>.</p>
<p>At the top of your script, write the following (<strong>with appropriate changes</strong>):</p>
<pre><code># Assignment: WPA 4
# Name: Laura Fontanesi
# Date: 5 April 2022</code></pre>
<div id="load-data-in-r" class="section level1">
<h1>Load data in R</h1>
<p>Download the data <code>ccam_original.sav</code> from the <a href="https://github.com/laurafontanesi/r-seminar22/tree/main/data">data folder on Github</a> and load them in R.</p>
<pre class="r"><code>library(tidyverse)
library(haven)

# Load data in R
survey_data_raw = read_spss(&quot;data/ccam_original.sav&quot;)</code></pre>
</div>
<div id="what-is-data-wrangling" class="section level1">
<h1>1. What is data wrangling?</h1>
<p>Data wrangling is the process of transforming data from a raw format (in which they were collected) into another format with the intent of making it more appropriate and valuable for exploratory and confirmatory data analyses.</p>
<p>Today’s class is based on specific functions in the tidyverse that will serve exactly this purpuse.</p>
</div>
<div id="functions-to-know-and-some-examples" class="section level1">
<h1>2. Functions to know and some examples</h1>
<p>Virtually all you need to know is in <a href="https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf">this cheatsheet</a>.</p>
<p>The more frequent functions you will use are:</p>
<ul>
<li><p><code>%&gt;%</code>: The pipe operator, to chain functions (not recommended at the beginning).</p></li>
<li><p><code>arrange</code>: order the dataframe based on values of variables.</p></li>
<li><p><code>rename</code>: to rename specific columns.</p></li>
<li><p><code>filter</code> and <code>slice</code>: to select subsets of rows.</p></li>
<li><p><code>select</code>: to select subsets of columns.</p></li>
<li><p><code>mutate</code>: make new columns based on modifications of existing ones.</p></li>
<li><p><code>mutate_all</code>: make the same modification on all columns.</p></li>
<li><p><code>mutate_if</code>: make the same modification on columns satisfying specific conditions.</p></li>
</ul>
<p>Look <a href="https://dplyr.tidyverse.org/reference/mutate_all.html">here</a> for other kinds of mutate.</p>
<ul>
<li><p><code>summarize</code>: to calculate summary statistics.</p></li>
<li><p><code>summarize_all</code>: to calculate summary statistics on all columns.</p></li>
<li><p><code>summarize_if</code>: to calculate summary statistics on columns satisfying specific conditions.</p></li>
</ul>
<p>Look <a href="https://dplyr.tidyverse.org/reference/summarise_all.html">here</a> for other kinds of summarize.</p>
<ul>
<li><p><code>group_by</code>: to group the data based on some variables, so that subsequent calculations are done on such variables.</p></li>
<li><p><code>full_join</code>, <code>left_join</code>, <code>right_join</code>: to join separate dataframes.</p></li>
<li><p><code>bind_rows</code> and <code>bind_cols</code>: to append dataframes vertically or horizontally.</p></li>
<li><p><code>gather</code> and <code>spread</code>: bring wide form to long form and viceversa.</p></li>
<li><p><code>unite</code>: make a column from multiple columns.</p></li>
<li><p><code>separate</code>: make multiple columns from one column.</p></li>
</ul>
<div id="ways-to-see-the-data-glimpse-sort-head-and-tail" class="section level2">
<h2>Ways to “see” the data: Glimpse, sort, head, and tail</h2>
<p>The first thing you want to do when importing data, is to inspect it visually, to get to know the information it contains. You can always click on the data in the Environment tab, but there are also other useful functions that allow us to see the data types (<code>glimpse</code>), to sort the data based on the values of one or more clomuns (<code>arrange</code>), and to visualize the first or the last n rows (<code>head</code> and <code>tail</code>, respectively).</p>
<pre class="r"><code>glimpse(survey_data_raw)</code></pre>
<pre><code>## Rows: 20,024
## Columns: 54
## $ case_ID                     &lt;dbl&gt; 2, 3, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27…
## $ wave                        &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ year                        &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ weight_wave                 &lt;dbl&gt; 0.54, 0.85, 0.49, 0.29, 1.29, 2.56, 0.23, 0.82, 0.38, 0.35, 0.91, 1.01, 0.82, 0.41,…
## $ weight_aggregate            &lt;dbl&gt; 0.29392628, 0.46266174, 0.26671088, 0.15784930, 0.70215723, 1.39342829, 0.12519082,…
## $ happening                   &lt;dbl+lbl&gt; 3, 2, 2, 3, 3, 2, 3, 1, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2…
## $ cause_original              &lt;dbl+lbl&gt; 1, 1, 2, 2, 1, 2, 1, 1, 4, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 2, 2, 2, 1, 1, 2…
## $ cause_other_text            &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;both of the above&quot;, &quot;&quot;, &quot;&quot;…
## $ cause_recoded               &lt;dbl+lbl&gt; 6, 6, 4, 4, 6, 4, 6, 6, 3, 4, 6, 6, 6, 6, 5, 4, 6, 6, 6, 5, 6, 4, 4, 4, 6, 6, 4…
## $ sci_consensus               &lt;dbl+lbl&gt; 4, 1, 2, 4, 2, 2, 2, 3, 2, 4, 1, 2, 4, 4, 4, 2, 2, 1, 4, 4, 4, 2, 2, 2, 4, 2, 2…
## $ worry                       &lt;dbl+lbl&gt; 3, 2, 1, 3, 3, 2, 3, 2, 1, 3, 2, 3, 3, 3, 4, 2, 4, 2, 4, 1, 3, 1, 2, 2, 2, 2, 3…
## $ harm_personally             &lt;dbl+lbl&gt; 2, 2, 1, 2, 0, 0, 2, 3, 1, 0, 0, 1, 3, 2, 4, 2, 3, 3, 3, 1, 3, 1, 2, 2, 1, 3, 3…
## $ harm_US                     &lt;dbl+lbl&gt;  3, -1,  1,  2,  0,  0,  3,  3,  1,  0,  0,  0,  3,  2,  4,  2,  3,  3,  3,  1,…
## $ harm_dev_countries          &lt;dbl+lbl&gt; 4, 2, 1, 3, 0, 0, 4, 3, 1, 0, 0, 0, 4, 2, 4, 2, 4, 0, 3, 1, 4, 1, 2, 2, 3, 4, 4…
## $ harm_future_gen             &lt;dbl+lbl&gt;  4,  3,  1,  3,  0,  0,  4,  3,  1,  4,  0,  0,  4,  3,  4,  3,  4,  0,  4,  1,…
## $ harm_plants_animals         &lt;dbl+lbl&gt; 4, 3, 1, 3, 3, 0, 4, 3, 1, 4, 0, 3, 4, 2, 4, 3, 4, 3, 4, 1, 4, 1, 2, 3, 3, 4, 4…
## $ when_harm_US                &lt;dbl+lbl&gt; 5, 3, 1, 4, 2, 2, 5, 4, 1, 3, 3, 3, 5, 4, 5, 2, 5, 6, 6, 1, 6, 1, 2, 2, 4, 6, 6…
## $ reg_CO2_pollutant           &lt;dbl+lbl&gt;  4,  3,  2,  3,  3,  1,  3,  2,  2,  3,  3,  4,  4,  3,  3,  2,  3,  4,  4,  4,…
## $ reg_utilities               &lt;dbl+lbl&gt;  4,  3,  1,  4,  1,  1,  2,  2,  2,  4,  3,  1,  4,  3,  2,  2,  3,  1,  4,  4,…
## $ fund_research               &lt;dbl+lbl&gt;  4,  3,  1,  4,  4,  3,  4,  2,  3,  4,  3,  1,  3,  3,  4,  3,  4,  3,  4,  4,…
## $ reg_coal_emissions          &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ discuss_GW                  &lt;dbl+lbl&gt; 3, 2, 1, 2, 1, 2, 3, 2, 3, 3, 2, 2, 2, 1, 3, 2, 2, 1, 3, 1, 4, 1, 2, 2, 2, 2, 1…
## $ hear_GW_media               &lt;dbl+lbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
## $ gender                      &lt;dbl+lbl&gt; 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2…
## $ age                         &lt;dbl&gt; 78, 45, 54, 71, 26, 29, 29, 34, 46, 60, 65, 67, 68, 60, 63, 32, 44, 76, 38, 45, 40,…
## $ age_category                &lt;dbl+lbl&gt; 3, 2, 2, 3, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 1, 2, 3, 2, 2, 2, 3, 2, 1, 3, 1, 3…
## $ generation                  &lt;dbl+lbl&gt; 5, 4, 4, 5, 2, 3, 3, 3, 4, 4, 5, 5, 5, 4, 5, 3, 4, 5, 3, 4, 3, 5, 3, 3, 5, 2, 5…
## $ educ                        &lt;dbl+lbl&gt;  9,  6, 14, 13, 10, 12, 12, 12, 12, 12,  9, 14,  9, 10,  9, 13, 12,  9, 12, 11,…
## $ educ_category               &lt;dbl+lbl&gt; 2, 1, 4, 4, 3, 4, 4, 4, 4, 4, 2, 4, 2, 3, 2, 4, 4, 2, 4, 3, 4, 2, 4, 2, 4, 4, 3…
## $ income                      &lt;dbl+lbl&gt; 12,  9,  9, 16, 13, 14,  3, 12, 16, 17,  8,  7, 16,  1,  7, 16, 16,  7,  8, 13,…
## $ income_category             &lt;dbl+lbl&gt; 2, 1, 1, 3, 2, 2, 1, 2, 3, 3, 1, 1, 3, 1, 1, 3, 3, 1, 1, 2, 3, 1, 2, 2, 1, 2, 1…
## $ race                        &lt;dbl+lbl&gt; 1, 1, 4, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1…
## $ ideology                    &lt;dbl+lbl&gt; 4, 3, 4, 4, 4, 5, 4, 2, 4, 5, 3, 4, 3, 3, 1, 4, 2, 3, 2, 4, 2, 5, 5, 3, 1, 2, 3…
## $ party                       &lt;dbl+lbl&gt; 1, 5, 1, 3, 1, 3, 1, 3, 3, 1, 2, 1, 3, 2, 2, 1, 2, 2, 3, 5, 2, 1, 1, 3, 2, 2, 3…
## $ party_w_leaners             &lt;dbl+lbl&gt; 1, 4, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 4, 2, 1, 1, 1, 2, 2, 3…
## $ party_x_ideo                &lt;dbl+lbl&gt;  5, -2,  5,  5,  5,  5,  5,  3,  3,  5,  2,  5,  2,  2,  1,  5,  1,  2,  1, -2,…
## $ registered_voter            &lt;dbl+lbl&gt; 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1…
## $ region9                     &lt;dbl+lbl&gt; 5, 3, 8, 5, 6, 9, 8, 8, 2, 7, 5, 7, 2, 4, 7, 7, 4, 2, 1, 5, 8, 5, 3, 7, 5, 1, 9…
## $ region4                     &lt;dbl+lbl&gt; 3, 2, 4, 3, 3, 4, 4, 4, 1, 3, 3, 3, 1, 2, 3, 3, 2, 1, 1, 3, 4, 3, 2, 3, 3, 1, 4…
## $ religion                    &lt;dbl+lbl&gt;  2,  2,  4,  2,  1, 11,  4, 15,  2,  1,  2,  2,  5,  3,  1, 11,  2,  2, 15, 11,…
## $ religion_other_nonchristian &lt;chr&gt; &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;,…
## $ evangelical                 &lt;dbl+lbl&gt; 2, 3, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 3, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1…
## $ service_attendance          &lt;dbl+lbl&gt; 5, 2, 5, 2, 5, 5, 5, 1, 5, 4, 3, 2, 2, 1, 5, 5, 5, 3, 1, 5, 3, 6, 5, 2, 2, 2, 2…
## $ marit_status                &lt;dbl+lbl&gt; 2, 5, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3, 1, 3, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 3, 5, 1…
## $ employment                  &lt;dbl+lbl&gt; 5, 6, 4, 5, 1, 2, 1, 1, 2, 7, 1, 5, 5, 5, 1, 7, 1, 5, 1, 1, 1, 5, 1, 1, 5, 1, 5…
## $ house_head                  &lt;dbl+lbl&gt; 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…
## $ house_size                  &lt;dbl&gt; 3, 2, 2, 2, 2, 3, 2, 2, 2, 4, 1, 1, 2, 1, 2, 3, 4, 2, 1, 5, 3, 3, 3, 4, 1, 1, 2, 2,…
## $ house_ages0to1              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ house_ages2to5              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ house_ages6to12             &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0,…
## $ house_ages13to17            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ house_ages18plus            &lt;dbl&gt; 3, 2, 2, 2, 2, 2, 2, 2, 2, 4, 1, 1, 2, 1, 2, 2, 2, 2, 1, 3, 2, 3, 2, 2, 1, 1, 2, 2,…
## $ house_type                  &lt;dbl+lbl&gt; 1, 4, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 1, 1, 3, 3, 4…
## $ house_own                   &lt;dbl+lbl&gt; 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1…</code></pre>
<pre class="r"><code># sort by one variable, and only show the first 6 values
head(arrange(survey_data_raw, wave), 6)</code></pre>
<pre><code>## # A tibble: 6 x 54
##   case_ID         wave      year weight_wave weight_aggregate      happening cause_original cause_other_text cause_recoded
##     &lt;dbl&gt;    &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl+lbl&gt;      &lt;dbl+lbl&gt; &lt;chr&gt;                &lt;dbl+lbl&gt;
## 1       2 1 [Nov 2008]  1 [2008]        0.54            0.294 3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
## 2       3 1 [Nov 2008]  1 [2008]        0.85            0.463 2 [Don&#39;t know] 1 [Caused mos… &quot;&quot;               6 [Caused mo…
## 3       5 1 [Nov 2008]  1 [2008]        0.49            0.267 2 [Don&#39;t know] 2 [Caused mos… &quot;&quot;               4 [Caused mo…
## 4       6 1 [Nov 2008]  1 [2008]        0.29            0.158 3 [Yes]        2 [Caused mos… &quot;&quot;               4 [Caused mo…
## 5       7 1 [Nov 2008]  1 [2008]        1.29            0.702 3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
## 6       8 1 [Nov 2008]  1 [2008]        2.56            1.39  2 [Don&#39;t know] 2 [Caused mos… &quot;&quot;               4 [Caused mo…
## # … with 45 more variables: sci_consensus &lt;dbl+lbl&gt;, worry &lt;dbl+lbl&gt;, harm_personally &lt;dbl+lbl&gt;, harm_US &lt;dbl+lbl&gt;,
## #   harm_dev_countries &lt;dbl+lbl&gt;, harm_future_gen &lt;dbl+lbl&gt;, harm_plants_animals &lt;dbl+lbl&gt;, when_harm_US &lt;dbl+lbl&gt;,
## #   reg_CO2_pollutant &lt;dbl+lbl&gt;, reg_utilities &lt;dbl+lbl&gt;, fund_research &lt;dbl+lbl&gt;, reg_coal_emissions &lt;dbl+lbl&gt;,
## #   discuss_GW &lt;dbl+lbl&gt;, hear_GW_media &lt;dbl+lbl&gt;, gender &lt;dbl+lbl&gt;, age &lt;dbl&gt;, age_category &lt;dbl+lbl&gt;,
## #   generation &lt;dbl+lbl&gt;, educ &lt;dbl+lbl&gt;, educ_category &lt;dbl+lbl&gt;, income &lt;dbl+lbl&gt;, income_category &lt;dbl+lbl&gt;,
## #   race &lt;dbl+lbl&gt;, ideology &lt;dbl+lbl&gt;, party &lt;dbl+lbl&gt;, party_w_leaners &lt;dbl+lbl&gt;, party_x_ideo &lt;dbl+lbl&gt;,
## #   registered_voter &lt;dbl+lbl&gt;, region9 &lt;dbl+lbl&gt;, region4 &lt;dbl+lbl&gt;, religion &lt;dbl+lbl&gt;, …</code></pre>
<pre class="r"><code># sort by 2 variables (one in opposite order), and only show the last 10 values
tail(arrange(survey_data_raw, wave, desc(year)), 10)</code></pre>
<pre><code>## # A tibble: 10 x 54
##    case_ID          wave      year weight_wave weight_aggregate      happening cause_original cause_other_text cause_recoded
##      &lt;dbl&gt;     &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;       &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl+lbl&gt;      &lt;dbl+lbl&gt; &lt;chr&gt;                &lt;dbl+lbl&gt;
##  1   35442 17 [Oct 2017]  9 [2017]       1.29             1.17  3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
##  2   35443 17 [Oct 2017]  9 [2017]       0.502            0.454 3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
##  3   35445 17 [Oct 2017]  9 [2017]       0.879            0.794 3 [Yes]        2 [Caused mos… &quot;&quot;               4 [Caused mo…
##  4   35446 17 [Oct 2017]  9 [2017]       0.759            0.686 3 [Yes]        2 [Caused mos… &quot;&quot;               4 [Caused mo…
##  5   35448 17 [Oct 2017]  9 [2017]       1.39             1.25  3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
##  6   35450 17 [Oct 2017]  9 [2017]       1.35             1.22  3 [Yes]        2 [Caused mos… &quot;&quot;               4 [Caused mo…
##  7   35451 17 [Oct 2017]  9 [2017]       0.911            0.823 3 [Yes]        3 [Other (Ple… &quot;combination of… 5 [Caused by…
##  8   35452 17 [Oct 2017]  9 [2017]       1.04             0.936 3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
##  9   35454 17 [Oct 2017]  9 [2017]       0.606            0.547 2 [Don&#39;t know] 2 [Caused mos… &quot;&quot;               4 [Caused mo…
## 10   35455 17 [Oct 2017]  9 [2017]       1.18             1.06  3 [Yes]        1 [Caused mos… &quot;&quot;               6 [Caused mo…
## # … with 45 more variables: sci_consensus &lt;dbl+lbl&gt;, worry &lt;dbl+lbl&gt;, harm_personally &lt;dbl+lbl&gt;, harm_US &lt;dbl+lbl&gt;,
## #   harm_dev_countries &lt;dbl+lbl&gt;, harm_future_gen &lt;dbl+lbl&gt;, harm_plants_animals &lt;dbl+lbl&gt;, when_harm_US &lt;dbl+lbl&gt;,
## #   reg_CO2_pollutant &lt;dbl+lbl&gt;, reg_utilities &lt;dbl+lbl&gt;, fund_research &lt;dbl+lbl&gt;, reg_coal_emissions &lt;dbl+lbl&gt;,
## #   discuss_GW &lt;dbl+lbl&gt;, hear_GW_media &lt;dbl+lbl&gt;, gender &lt;dbl+lbl&gt;, age &lt;dbl&gt;, age_category &lt;dbl+lbl&gt;,
## #   generation &lt;dbl+lbl&gt;, educ &lt;dbl+lbl&gt;, educ_category &lt;dbl+lbl&gt;, income &lt;dbl+lbl&gt;, income_category &lt;dbl+lbl&gt;,
## #   race &lt;dbl+lbl&gt;, ideology &lt;dbl+lbl&gt;, party &lt;dbl+lbl&gt;, party_w_leaners &lt;dbl+lbl&gt;, party_x_ideo &lt;dbl+lbl&gt;,
## #   registered_voter &lt;dbl+lbl&gt;, region9 &lt;dbl+lbl&gt;, region4 &lt;dbl+lbl&gt;, religion &lt;dbl+lbl&gt;, …</code></pre>
</div>
<div id="select-or-drop-specific-columns-and-rows-indexing" class="section level2">
<h2>Select or drop specific columns and rows (indexing)</h2>
<p>In basic R, we saw that we can select specific columns and rows using indexing. In tidyverse, we have <code>select</code> (for columns based on column labels, similar to indexing with character vectors or with the <code>$</code> operator), <code>filter</code> (for rows based on values, similar to indexing with logical vectors) and <code>slice</code> (for rows based on row numbers, similar to indexing with a numerical vector).</p>
<pre class="r"><code>interesting_columns = c(&#39;wave&#39;, &#39;year&#39;, &#39;happening&#39;, &#39;cause_recoded&#39;, &#39;sci_consensus&#39;, &#39;worry&#39;, &#39;harm_personally&#39;, 
                        &#39;harm_US&#39;, &#39;harm_dev_countries&#39;, &#39;harm_future_gen&#39;, &#39;harm_plants_animals&#39;, &#39;when_harm_US&#39;,
                        &#39;reg_CO2_pollutant&#39;, &#39;reg_utilities&#39;, &#39;fund_research&#39;, &#39;discuss_GW&#39;,
                        &#39;gender&#39;, &#39;age_category&#39;, &#39;educ_category&#39;, &#39;income_category&#39;, &#39;race&#39;, &#39;party_x_ideo&#39;, &#39;region4&#39;, &#39;employment&#39;)

columns_to_drop = c(&#39;case_ID&#39;, &#39;weight_wave&#39;, &#39;weight_aggregate&#39;, &#39;cause_original&#39;, &#39;cause_other_text&#39;,
                    &#39;reg_coal_emissions&#39;, &#39;hear_GW_media&#39;, &#39;age&#39;, &#39;generation&#39;, &#39;educ&#39;, &#39;income&#39;, &#39;ideology&#39;,
                    &#39;party&#39;, &#39;party_w_leaners&#39;, &#39;registered_voter&#39;, &#39;region9&#39;, &#39;religion&#39;, &#39;religion_other_nonchristian&#39;,
                    &#39;evangelical&#39;, &#39;service_attendance&#39;, &#39;marit_status&#39;, &#39;house_head&#39;, &#39;house_size&#39;,
                    &#39;house_ages0to1&#39;, &#39;house_ages2to5&#39;, &#39;house_ages6to12&#39;, &#39;house_ages13to17&#39;, &#39;house_ages18plus&#39;,
                    &#39;house_type&#39;, &#39;house_own&#39;)

# use all_of to inlcude columns
survey_data = select(survey_data_raw, all_of(interesting_columns))

# use -all_of to exclude columns
survey_data = select(survey_data_raw, -all_of(columns_to_drop))</code></pre>
<pre class="r"><code># equivalent to survey_data[200:210,]
slice(survey_data, 200:210)</code></pre>
<pre><code>## # A tibble: 11 x 24
##            wave      year happening cause_recoded sci_consensus   worry harm_personally harm_US harm_dev_countr… harm_future_gen
##       &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt; &lt;dbl+l&gt;       &lt;dbl+lbl&gt; &lt;dbl+l&gt;        &lt;dbl+lbl&gt;       &lt;dbl+lbl&gt;
##  1 1 [Nov 2008]  1 [2008] 3 [Yes]   5 [Caused by… 2 [There is … 1 [Not… 1 [Not at all]  3 [A m… 3 [A moderate a… 4 [A great dea…
##  2 1 [Nov 2008]  1 [2008] 2 [Don&#39;t… 4 [Caused mo… 2 [There is … 3 [Som… 0 [Don&#39;t know]  0 [Don… 0 [Don&#39;t know]   0 [Don&#39;t know] 
##  3 1 [Nov 2008]  1 [2008] 1 [No]    4 [Caused mo… 2 [There is … 1 [Not… 1 [Not at all]  1 [Not… 1 [Not at all]   1 [Not at all] 
##  4 1 [Nov 2008]  1 [2008] 2 [Don&#39;t… 4 [Caused mo… 2 [There is … 2 [Not… 1 [Not at all]  1 [Not… 1 [Not at all]   0 [Don&#39;t know] 
##  5 1 [Nov 2008]  1 [2008] 1 [No]    4 [Caused mo… 2 [There is … 1 [Not… 1 [Not at all]  3 [A m… 1 [Not at all]   1 [Not at all] 
##  6 1 [Nov 2008]  1 [2008] 3 [Yes]   6 [Caused mo… 4 [Most scie… 3 [Som… 3 [A moderate … 3 [A m… 3 [A moderate a… 4 [A great dea…
##  7 1 [Nov 2008]  1 [2008] 3 [Yes]   6 [Caused mo… 4 [Most scie… 4 [Ver… 2 [Only a litt… 3 [A m… 4 [A great deal] 4 [A great dea…
##  8 1 [Nov 2008]  1 [2008] 3 [Yes]   5 [Caused by… 4 [Most scie… 3 [Som… 3 [A moderate … 3 [A m… 3 [A moderate a… 4 [A great dea…
##  9 1 [Nov 2008]  1 [2008] 3 [Yes]   6 [Caused mo… 4 [Most scie… 1 [Not… 1 [Not at all]  1 [Not… 1 [Not at all]   1 [Not at all] 
## 10 1 [Nov 2008]  1 [2008] 3 [Yes]   6 [Caused mo… 4 [Most scie… 3 [Som… 3 [A moderate … 4 [A g… 4 [A great deal] 4 [A great dea…
## 11 1 [Nov 2008]  1 [2008] 1 [No]    4 [Caused mo… 2 [There is … 1 [Not… 1 [Not at all]  1 [Not… 1 [Not at all]   1 [Not at all] 
## # … with 14 more variables: harm_plants_animals &lt;dbl+lbl&gt;, when_harm_US &lt;dbl+lbl&gt;, reg_CO2_pollutant &lt;dbl+lbl&gt;,
## #   reg_utilities &lt;dbl+lbl&gt;, fund_research &lt;dbl+lbl&gt;, discuss_GW &lt;dbl+lbl&gt;, gender &lt;dbl+lbl&gt;, age_category &lt;dbl+lbl&gt;,
## #   educ_category &lt;dbl+lbl&gt;, income_category &lt;dbl+lbl&gt;, race &lt;dbl+lbl&gt;, party_x_ideo &lt;dbl+lbl&gt;, region4 &lt;dbl+lbl&gt;,
## #   employment &lt;dbl+lbl&gt;</code></pre>
<pre class="r"><code># eliminate people (i.e., rows) who didn&#39;t reply in some variables of interest (an absence of reply was coded as -1 here)
survey_data = filter(survey_data, 
                     happening &gt; 0, 
                     cause_recoded &gt; 0, 
                     sci_consensus &gt; 0, 
                     worry &gt; 0)</code></pre>
</div>
<div id="change-values-or-value-types-indexing-and-reassigning" class="section level2">
<h2>Change values or value types (indexing and reassigning)</h2>
<p>In basic R, we saw that we can change information in the dataset by indexing specific columns and/or rows and reassigning values to them. In tidyverse we have specific functions that do this directly: the <code>mutate</code> functions. <code>mutate_all</code> applies one transforming function to all columns, while <code>mutate</code> allows to to do specific changes to single columns.</p>
<pre class="r"><code># convert all data to integers type
survey_data = mutate_all(survey_data, 
                         as.integer)</code></pre>
<p>Note that when you use an existing column label, the column is replaced with the new values. If you want to simply add a column based on the values of an existing one, use a non-existing label instead.</p>
<pre class="r"><code>survey_data = mutate(survey_data, 
                     happening_cont = happening + rnorm(mean=0, sd=.5, n=nrow(survey_data)),
                     worry_cont = worry + rnorm(mean=0, sd=.5, n=nrow(survey_data)),
                     year=recode(year, 
                                 `1` = 2008,
                                 `2` = 2010,
                                 `3` = 2011,
                                 `4` = 2012, 
                                 `5` = 2013,
                                 `6` = 2014,
                                 `7` = 2015,
                                 `8` = 2016,
                                 `9` = 2017),
                     happening_labels=recode(happening,
                                             `1` = &quot;no&quot;,
                                             `2` = &quot;dont know&quot;,
                                             `3` = &quot;yes&quot;),
                     cause_recoded=recode(cause_recoded,
                                          `1` = &quot;dont know&quot;,
                                          `2` = &quot;other&quot;,
                                          `3` = &quot;not happening&quot;,
                                          `4` = &quot;natural&quot;,
                                          `5` = &quot;human&quot;,
                                          `6` = &quot;natural and human&quot;),
                     sci_consensus=recode(sci_consensus,
                                          `1` = &quot;dont know&quot;,
                                          `2` = &quot;disagreement&quot;,
                                          `3` = &quot;not happening&quot;,
                                          `4` = &quot;happening&quot;),
                     gender=recode(gender,
                                   `1` = &quot;male&quot;,
                                   `2` = &quot;female&quot;),
                     age_category_labels=recode(age_category,
                                                `1` = &quot;18-34&quot;,
                                                `2` = &quot;35-54&quot;,
                                                `3` = &quot;55+&quot;),
                     educ_category_labels=recode(educ_category,
                                                 `1` = &quot;no highschool&quot;,
                                                 `2` = &quot;highschool&quot;,
                                                 `3` = &quot;college&quot;,
                                                 `4` = &quot;bachelor or higher&quot;),
                     income_category_labels=recode(income_category,
                                                   `1` = &quot;less 50000&quot;,
                                                   `2` = &quot;50000-99999&quot;,
                                                   `3` = &quot;more 100000&quot;),
                     race=recode(race,
                                 `1` = &#39;white non hisp&#39;,
                                 `2` = &#39;black non hisp&#39;,
                                 `3` = &#39;other non hisp&#39;,
                                 `4` = &#39;hisp&#39;),
                     party_x_ideo=recode(party_x_ideo,
                                         `-2` = &quot;no interest&quot;,
                                         `-1` = &quot;refused&quot;,
                                         `1` = &quot;liberal democrat&quot;,
                                         `2` = &quot;moderate democrate&quot;,
                                         `3` = &quot;independent&quot;,
                                         `4` = &quot;moderate republican&quot;,
                                         `5` = &quot;conservative republican&quot;),
                     region4 = recode(region4,
                                      `1` = &quot;northeast&quot;,
                                      `2` = &quot;midwest&quot;,
                                      `3` = &quot;south&quot;,
                                      `4` = &quot;west&quot;),
                     employment = recode(employment,
                                         `1` = &quot;Working/as a paid employee&quot;,
                                         `2` = &quot;Working/selfemploye&quot;,
                                         `3` = &quot;Not working/temporary&quot;,
                                         `4` = &quot;Not working/looking&quot;,
                                         `5` = &quot;Not working/retired&quot;,
                                         `6` = &quot;Not working/disabled&quot;,
                                         `7` = &quot;Not working/other&quot;))</code></pre>
</div>
<div id="compute-summary-statistics" class="section level2">
<h2>Compute summary statistics</h2>
<p>Another way to inspect the data, is to compute summary statistics (like mean, SD, quantiles, percentages, etc.) on each column. In tidyverse, the function <code>summarise</code> allows you to specify what to compute for each column:</p>
<pre class="r"><code>summarise(survey_data, 
          count=n(), 
          min_worry=min(worry_cont),
          quantile25_worry=quantile(worry_cont, .25, na.rm = TRUE),
          mean_worry=mean(worry_cont), 
          quantile75_worry=quantile(worry_cont, .75, na.rm = TRUE),
          max_worry=max(worry_cont),
          min_happening=min(happening_cont),
          quantile25_happening=quantile(happening_cont, .25, na.rm = TRUE),
          mean_happening=mean(happening_cont),
          quantile75_happening=quantile(happening_cont, .75, na.rm = TRUE),
          max_happening=max(happening_cont))</code></pre>
<pre><code>## # A tibble: 1 x 11
##   count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happeni… mean_happening
##   &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;               &lt;dbl&gt;          &lt;dbl&gt;
## 1 18514     -1.09             1.74       2.52             3.28      5.78        -0.487                1.96           2.50
## # … with 2 more variables: quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
<pre class="r"><code>summarise(survey_data,
          mean_happening = mean(happening))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_happening
##            &lt;dbl&gt;
## 1           2.50</code></pre>
<p>By default, <code>summarise</code> computes statistics on the whole dataset. However, when you have different experimental conditions and/or hierarchical data (repeated measures, longitudinal data, multi-site data, etc.), you might want to compute different stats per group/level defined by a categorical variable (the one that would specify the condition/group). In tidyverse, this can be achieved by using the <code>group_by</code> function together with the <code>summarise</code> function:</p>
<pre class="r"><code>grouped_data = group_by(survey_data, year)

summarise(grouped_data, 
          count=n(), 
          min_worry=min(worry_cont),
          quantile25_worry=quantile(worry_cont, .25, na.rm = TRUE),
          mean_worry=mean(worry_cont), 
          quantile75_worry=quantile(worry_cont, .75, na.rm = TRUE),
          max_worry=max(worry_cont),
          min_happening=min(happening_cont),
          quantile25_happening=quantile(happening_cont, .25, na.rm = TRUE),
          mean_happening=mean(happening_cont),
          quantile75_happening=quantile(happening_cont, .75, na.rm = TRUE),
          max_happening=max(happening_cont))</code></pre>
<pre><code>## # A tibble: 9 x 12
##    year count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happening
##   &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;
## 1  2008  2130    -0.494             1.93       2.63             3.35      5.78        -0.487                 2.09
## 2  2010  1993    -0.324             1.60       2.40             3.14      5.25        -0.408                 1.68
## 3  2011  1946    -1.09              1.67       2.43             3.16      5.33        -0.376                 1.85
## 4  2012  2050    -0.503             1.77       2.52             3.28      5.19        -0.434                 2.02
## 5  2013  1858    -0.356             1.63       2.48             3.26      5.68        -0.180                 1.90
## 6  2014  2282    -0.258             1.70       2.49             3.25      5.65        -0.448                 1.89
## 7  2015  1263    -0.727             1.65       2.44             3.25      5.10        -0.438                 1.73
## 8  2016  2427    -0.285             1.78       2.57             3.35      5.48        -0.283                 2.10
## 9  2017  2565    -0.627             1.84       2.61             3.40      5.63        -0.400                 2.12
## # … with 3 more variables: mean_happening &lt;dbl&gt;, quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
</div>
<div id="split-character-columns" class="section level2">
<h2>Split character columns</h2>
<p>Sometimes, we get data with categorical variables that contain more than one variable. For example, in our dataset, in the <code>employment</code> column, we have information about whether the person is working or is unemployed (this is one categorical variable with 2 levels) and about the working type (this is another categorical variable with as many levels as there are employment types).</p>
<p>With the <code>separate</code> function we can indeed separate this information based on specific text separators (in this case, <code>/</code>):</p>
<pre class="r"><code>survey_data = separate(survey_data,
                       col = employment,
                       into = c(&#39;working&#39;, &#39;working_type&#39;),
                       sep = &#39;/&#39;,
                       remove = FALSE)
head(select(survey_data, employment, working, working_type), 10)</code></pre>
<pre><code>## # A tibble: 10 x 3
##    employment                 working     working_type      
##    &lt;chr&gt;                      &lt;chr&gt;       &lt;chr&gt;             
##  1 Not working/retired        Not working retired           
##  2 Not working/disabled       Not working disabled          
##  3 Not working/looking        Not working looking           
##  4 Not working/retired        Not working retired           
##  5 Working/as a paid employee Working     as a paid employee
##  6 Working/selfemploye        Working     selfemploye       
##  7 Working/as a paid employee Working     as a paid employee
##  8 Working/as a paid employee Working     as a paid employee
##  9 Working/selfemploye        Working     selfemploye       
## 10 Not working/other          Not working other</code></pre>
<p>You can also create a new column via <code>mutate</code> and the <code>case_when</code> function for specific categories you are interested in your analysis:</p>
<pre class="r"><code>survey_data = mutate(survey_data,
                     working_recoded = case_when(working == &quot;Not working&quot; &amp; working_type == &#39;looking&#39; ~ 0,
                                                 working == &quot;Not working&quot; &amp; working_type != &#39;looking&#39; ~ 1,
                                                 working == &quot;Working&quot; ~ 2))
                     
head(select(survey_data, employment, working, working_type, working_recoded), 10)</code></pre>
<pre><code>## # A tibble: 10 x 4
##    employment                 working     working_type       working_recoded
##    &lt;chr&gt;                      &lt;chr&gt;       &lt;chr&gt;                        &lt;dbl&gt;
##  1 Not working/retired        Not working retired                          1
##  2 Not working/disabled       Not working disabled                         1
##  3 Not working/looking        Not working looking                          0
##  4 Not working/retired        Not working retired                          1
##  5 Working/as a paid employee Working     as a paid employee               2
##  6 Working/selfemploye        Working     selfemploye                      2
##  7 Working/as a paid employee Working     as a paid employee               2
##  8 Working/as a paid employee Working     as a paid employee               2
##  9 Working/selfemploye        Working     selfemploye                      2
## 10 Not working/other          Not working other                            1</code></pre>
<p>Once you have these groups, you can calculate the statistics you are interested in:</p>
<pre class="r"><code>grouped_data = group_by(survey_data, working)

summarise(grouped_data, 
          count=n(), 
          min_worry=min(worry_cont),
          quantile25_worry=quantile(worry_cont, .25, na.rm = TRUE),
          mean_worry=mean(worry_cont), 
          quantile75_worry=quantile(worry_cont, .75, na.rm = TRUE),
          max_worry=max(worry_cont),
          min_happening=min(happening_cont),
          quantile25_happening=quantile(happening_cont, .25, na.rm = TRUE),
          mean_happening=mean(happening_cont),
          quantile75_happening=quantile(happening_cont, .75, na.rm = TRUE),
          max_happening=max(happening_cont))</code></pre>
<pre><code>## # A tibble: 2 x 12
##   working     count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happening
##   &lt;chr&gt;       &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;
## 1 Not working  7996    -1.09              1.71       2.51             3.28      5.68        -0.448                 1.95
## 2 Working     10518    -0.727             1.76       2.52             3.28      5.78        -0.487                 1.97
## # … with 3 more variables: mean_happening &lt;dbl&gt;, quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
<pre class="r"><code># first filter, and then get summary statistics per group
not_working_data = filter(survey_data, working == &quot;Not working&quot;)

grouped_data = group_by(not_working_data, working_type)

summarise(grouped_data, 
          count=n(), 
          min_worry=min(worry_cont),
          quantile25_worry=quantile(worry_cont, .25, na.rm = TRUE),
          mean_worry=mean(worry_cont), 
          quantile75_worry=quantile(worry_cont, .75, na.rm = TRUE),
          max_worry=max(worry_cont),
          min_happening=min(happening_cont),
          quantile25_happening=quantile(happening_cont, .25, na.rm = TRUE),
          mean_happening=mean(happening_cont),
          quantile75_happening=quantile(happening_cont, .75, na.rm = TRUE),
          max_happening=max(happening_cont))</code></pre>
<pre><code>## # A tibble: 5 x 12
##   working_type count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happening
##   &lt;chr&gt;        &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;
## 1 disabled      1259   -0.122              1.87       2.64             3.46      4.91       -0.141                  2.04
## 2 looking       1112   -0.226              1.91       2.63             3.34      5.31       -0.0399                 2.05
## 3 other         1370   -0.329              1.65       2.45             3.23      5.68       -0.420                  1.82
## 4 retired       4099   -1.09               1.63       2.45             3.22      5.34       -0.448                  1.93
## 5 temporary      156   -0.0456             1.96       2.65             3.45      5.10       -0.335                  1.85
## # … with 3 more variables: mean_happening &lt;dbl&gt;, quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
</div>
<div id="merge-character-columns" class="section level2">
<h2>Merge character columns</h2>
<p>As we have done in basic R with the <code>paste</code> function, we can also merge the values of two columns to create new groups we might be interested in. In tidyverse we use <code>unite</code>:</p>
<pre class="r"><code>survey_data = unite(survey_data,
                    &quot;race_gender&quot;,
                    race, 
                    gender,
                    sep = &quot;_&quot;,
                    remove=FALSE)

head(select(survey_data, race, gender, race_gender))</code></pre>
<pre><code>## # A tibble: 6 x 3
##   race           gender race_gender          
##   &lt;chr&gt;          &lt;chr&gt;  &lt;chr&gt;                
## 1 white non hisp female white non hisp_female
## 2 white non hisp male   white non hisp_male  
## 3 hisp           female hisp_female          
## 4 white non hisp male   white non hisp_male  
## 5 white non hisp female white non hisp_female
## 6 white non hisp male   white non hisp_male</code></pre>
<pre class="r"><code>grouped_data = group_by(survey_data, race_gender)

summarise(grouped_data, 
          count=n(), 
          min_worry=min(worry_cont),
          quantile25_worry=quantile(worry_cont, .25, na.rm = TRUE),
          mean_worry=mean(worry_cont), 
          quantile75_worry=quantile(worry_cont, .75, na.rm = TRUE),
          max_worry=max(worry_cont),
          min_happening=min(happening_cont),
          quantile25_happening=quantile(happening_cont, .25, na.rm = TRUE),
          mean_happening=mean(happening_cont),
          quantile75_happening=quantile(happening_cont, .75, na.rm = TRUE),
          max_happening=max(happening_cont))</code></pre>
<pre><code>## # A tibble: 8 x 12
##   race_gender           count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happ…
##   &lt;chr&gt;                 &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1 black non hisp_female   875   -0.324              1.90       2.60             3.30      5.48       -0.0661             2.27
## 2 black non hisp_male     724    0.252              1.97       2.63             3.30      5.13        0.246              2.25
## 3 hisp_female             875   -0.0215             2.19       2.82             3.55      5.68       -0.0672             2.22
## 4 hisp_male               919   -0.614              1.88       2.70             3.50      5.12       -0.283              2.13
## 5 other non hisp_female   562   -0.226              2.05       2.71             3.41      5.39       -0.0830             2.19
## 6 other non hisp_male     570   -0.267              1.83       2.60             3.37      4.91       -0.131              2.09
## 7 white non hisp_female  7000   -0.503              1.81       2.56             3.31      5.78       -0.448              2.00
## 8 white non hisp_male    6989   -1.09               1.54       2.37             3.15      5.34       -0.487              1.69
## # … with 3 more variables: mean_happening &lt;dbl&gt;, quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
<p>Or you can just use 2 grouping variables to compute statistics:</p>
<pre class="r"><code>grouped_data = group_by(survey_data, race, gender)

summarise(grouped_data, 
          count=n(), 
          min_worry=min(worry_cont),
          quantile25_worry=quantile(worry_cont, .25, na.rm = TRUE),
          mean_worry=mean(worry_cont), 
          quantile75_worry=quantile(worry_cont, .75, na.rm = TRUE),
          max_worry=max(worry_cont),
          min_happening=min(happening_cont),
          quantile25_happening=quantile(happening_cont, .25, na.rm = TRUE),
          mean_happening=mean(happening_cont),
          quantile75_happening=quantile(happening_cont, .75, na.rm = TRUE),
          max_happening=max(happening_cont))</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;race&#39;. You can override using the `.groups` argument.</code></pre>
<pre><code>## # A tibble: 8 x 13
## # Groups:   race [4]
##   race           gender count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happ…
##   &lt;chr&gt;          &lt;chr&gt;  &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1 black non hisp female   875   -0.324              1.90       2.60             3.30      5.48       -0.0661             2.27
## 2 black non hisp male     724    0.252              1.97       2.63             3.30      5.13        0.246              2.25
## 3 hisp           female   875   -0.0215             2.19       2.82             3.55      5.68       -0.0672             2.22
## 4 hisp           male     919   -0.614              1.88       2.70             3.50      5.12       -0.283              2.13
## 5 other non hisp female   562   -0.226              2.05       2.71             3.41      5.39       -0.0830             2.19
## 6 other non hisp male     570   -0.267              1.83       2.60             3.37      4.91       -0.131              2.09
## 7 white non hisp female  7000   -0.503              1.81       2.56             3.31      5.78       -0.448              2.00
## 8 white non hisp male    6989   -1.09               1.54       2.37             3.15      5.34       -0.487              1.69
## # … with 3 more variables: mean_happening &lt;dbl&gt;, quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
</div>
</div>
<div id="pipes" class="section level1">
<h1>3. Pipes</h1>
<p>Until now, we have used the tidyverse functions as all other functions we have used in basic R:</p>
<pre><code>new_object = function1(old_object, some_argument)
new_object = function2(new_object, some_argument)
new_object = function3(new_object, some_argument)</code></pre>
<p>However, in tidyverse, we can compact this notation using pipes:</p>
<pre><code>new_object = old_object %&gt;%
  function1(some_argument) %&gt;%
  function2(some_argument) %&gt;%
  function3(some_argument)</code></pre>
<p>As you see, this allows us to define an analysis pipeline in which each computation is done on the results of the previous computation.</p>
<p>Here is how we could rewrite all previous computations from loading the raw data to the grouped summary statistics:</p>
<pre class="r"><code>survey_data_raw = read_spss(&quot;data/ccam_original.sav&quot;)

survey_data = survey_data_raw %&gt;%
    select(all_of(interesting_columns)) %&gt;%
    filter(happening &gt; 0, 
           cause_recoded &gt; 0, 
           sci_consensus &gt; 0, 
           worry &gt; 0)  %&gt;%
    mutate_all(as.integer) %&gt;%
    mutate(happening_cont = happening + rnorm(mean=0, sd=.5, n=n()),
           worry_cont = worry + rnorm(mean=0, sd=.5, n=n()),
           year=recode(year, 
                       `1` = 2008, 
                       `2` = 2010,
                       `3` = 2011,
                       `4` = 2012, 
                       `5` = 2013,
                       `6` = 2014,
                       `7` = 2015,
                       `8` = 2016,
                       `9` = 2017),
           happening_labels=recode(happening,
                                   `1` = &quot;no&quot;,
                                   `2` = &quot;dont know&quot;,
                                   `3` = &quot;yes&quot;),
           cause_recoded=recode(cause_recoded,
                                `1` = &quot;dont know&quot;,
                                `2` = &quot;other&quot;,
                                `3` = &quot;not happening&quot;,
                                `4` = &quot;natural&quot;,
                                `5` = &quot;human&quot;,
                                `6` = &quot;natural and human&quot;),
           sci_consensus=recode(sci_consensus,
                                `1` = &quot;dont know&quot;,
                                `2` = &quot;disagreement&quot;,
                                `3` = &quot;not happening&quot;,
                                `4` = &quot;happening&quot;),
           gender=recode(gender,
                         `1` = &quot;male&quot;,
                         `2` = &quot;female&quot;),
           age_category_labels=recode(age_category,
                                      `1` = &quot;18-34&quot;,
                                      `2` = &quot;35-54&quot;,
                                      `3` = &quot;55+&quot;),
           educ_category_labels=recode(educ_category,
                                       `1` = &quot;no highschool&quot;,
                                       `2` = &quot;highschool&quot;,
                                       `3` = &quot;college&quot;,
                                       `4` = &quot;bachelor or higher&quot;),
           income_category_labels=recode(income_category,
                        `1` = &quot;less 50000&quot;,
                        `2` = &quot;50000-99999&quot;,
                        `3` = &quot;more 100000&quot;),
           race=recode(race,
                      `1` = &#39;white non hisp&#39;,
                      `2` = &#39;black non hisp&#39;,
                      `3` = &#39;other non hisp&#39;,
                      `4` = &#39;hisp&#39;),
           party_x_ideo=recode(party_x_ideo,
                               `-2` = &quot;no interest&quot;,
                               `-1` = &quot;refused&quot;,
                               `1` = &quot;liberal democrat&quot;,
                               `2` = &quot;moderate democrate&quot;,
                               `3` = &quot;independent&quot;,
                               `4` = &quot;moderate republican&quot;,
                               `5` = &quot;conservative republican&quot;),
           region4 = recode(region4,
                            `1` = &quot;northeast&quot;,
                            `2` = &quot;midwest&quot;,
                            `3` = &quot;south&quot;,
                            `4` = &quot;west&quot;),
           employment = recode(employment,
                               `1` = &quot;Working/as a paid employee&quot;,
                               `2` = &quot;Working/selfemploye&quot;,
                               `3` = &quot;Not working/temporary&quot;,
                               `4` = &quot;Not working/looking&quot;,
                               `5` = &quot;Not working/retired&quot;,
                               `6` = &quot;Not working/disabled&quot;,
                               `7` = &quot;Not working/other&quot;)) %&gt;%
    separate(col = employment,
             into = c(&#39;working&#39;, &#39;working_type&#39;),
             sep = &#39;/&#39;) %&gt;%
    filter(working == &quot;Not working&quot;)  %&gt;%
    group_by(working_type) %&gt;%
    summarise(count=n(), 
              min_worry=min(worry_cont),
              quantile25_worry=quantile(worry_cont, .25),
              mean_worry=mean(worry_cont), 
              quantile75_worry=quantile(worry_cont, .75),
              max_worry=max(worry_cont),
              min_happening=min(happening_cont),
              quantile25_happening=quantile(happening_cont, .25),
              mean_happening=mean(happening_cont),
              quantile75_happening=quantile(happening_cont, .75),
              max_happening=max(happening_cont))</code></pre>
<pre class="r"><code>print(survey_data)</code></pre>
<pre><code>## # A tibble: 5 x 12
##   working_type count min_worry quantile25_worry mean_worry quantile75_worry max_worry min_happening quantile25_happening
##   &lt;chr&gt;        &lt;int&gt;     &lt;dbl&gt;            &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;
## 1 disabled      1259    -0.896             1.84       2.65             3.46      5.27       -0.379                  2.06
## 2 looking       1112    -0.312             1.90       2.61             3.32      5.37       -0.372                  2.09
## 3 other         1370    -0.405             1.60       2.44             3.26      5.42       -0.419                  1.78
## 4 retired       4099    -0.497             1.66       2.44             3.21      5.50       -0.626                  1.90
## 5 temporary      156    -0.198             1.80       2.61             3.46      4.84        0.0687                 1.94
## # … with 3 more variables: mean_happening &lt;dbl&gt;, quantile75_happening &lt;dbl&gt;, max_happening &lt;dbl&gt;</code></pre>
</div>
<div id="join-dataframes" class="section level1">
<h1>4. Join dataframes</h1>
<p>In basic R, we have seen how we can add separate dataframes using the <code>cbind</code> and <code>rbind</code> functions. The corresponding functions in tidyverse are <code>bind_cols</code> and <code>bind_rows</code>:</p>
<pre class="r"><code># Create fake data:
N = 15

mean_score_students = runif(N, 5, 10)
fake_data_first_batch = tibble( # same as data.frame but in tidyverse!
    student = 1:N,
    age = round(rnorm(N, 30, 5)),
    score_wpa1 = mean_score_students,
    score_wpa2 = mean_score_students*0.9 + rnorm(N, 0, 0.1),
    score_wpa3 = mean_score_students*0.5 + rnorm(N, 0, 1),
    score_wpa4 = mean_score_students*0.7 + rnorm(N, 0, 0.2)
)
print(fake_data_first_batch)</code></pre>
<pre><code>## # A tibble: 15 x 6
##    student   age score_wpa1 score_wpa2 score_wpa3 score_wpa4
##      &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1       1    35       8.49       7.89       5.20       6.07
##  2       2    28       8.33       7.39       3.52       5.82
##  3       3    27       6.65       6.03       6.07       4.49
##  4       4    34       9.52       8.54       4.30       7.01
##  5       5    35       9.46       8.52       3.87       6.83
##  6       6    26       8.76       7.87       4.62       6.29
##  7       7    38       6.84       6.25       4.78       4.94
##  8       8    33       5.38       4.95       3.66       3.61
##  9       9    28       6.81       6.28       3.00       4.85
## 10      10    33       6.42       5.63       1.47       4.51
## 11      11    34       8.22       7.44       3.13       5.95
## 12      12    31       7.34       6.45       2.80       5.26
## 13      13    30       7.86       7.07       4.08       5.48
## 14      14    29       6.00       5.34       4.26       4.22
## 15      15    27       5.95       5.34       1.56       4.08</code></pre>
<pre class="r"><code>mean_score_students = runif(N, 5, 10)
fake_data_second_batch = tibble( # same as data.frame but in tidyverse!
    student = (N+1):(2*N),
    age = round(rnorm(N, 30, 5)),
    score_wpa1 = mean_score_students,
    score_wpa2 = mean_score_students*0.9 + rnorm(N, 0, 0.1),
    score_wpa3 = mean_score_students*0.5 + rnorm(N, 0, 1)
)
print(fake_data_second_batch)</code></pre>
<pre><code>## # A tibble: 15 x 5
##    student   age score_wpa1 score_wpa2 score_wpa3
##      &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1      16    33       6.59       5.87       3.30
##  2      17    28       8.48       7.67       3.66
##  3      18    33       7.78       6.88       3.09
##  4      19    26       7.68       6.88       3.24
##  5      20    21       7.49       6.65       7.42
##  6      21    39       5.44       4.87       2.50
##  7      22    32       8.90       8.05       4.54
##  8      23    34       9.03       8.07       6.16
##  9      24    31       9.52       8.55       2.92
## 10      25    31       8.56       7.59       3.40
## 11      26    29       7.18       6.44       4.85
## 12      27    22       8.29       7.50       3.77
## 13      28    33       9.50       8.48       6.40
## 14      29    23       6.76       6.12       2.06
## 15      30    25       9.31       8.25       3.21</code></pre>
<pre class="r"><code>fake_data = bind_rows(fake_data_first_batch, fake_data_second_batch)
fake_data</code></pre>
<pre><code>## # A tibble: 30 x 6
##    student   age score_wpa1 score_wpa2 score_wpa3 score_wpa4
##      &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1       1    35       8.49       7.89       5.20       6.07
##  2       2    28       8.33       7.39       3.52       5.82
##  3       3    27       6.65       6.03       6.07       4.49
##  4       4    34       9.52       8.54       4.30       7.01
##  5       5    35       9.46       8.52       3.87       6.83
##  6       6    26       8.76       7.87       4.62       6.29
##  7       7    38       6.84       6.25       4.78       4.94
##  8       8    33       5.38       4.95       3.66       3.61
##  9       9    28       6.81       6.28       3.00       4.85
## 10      10    33       6.42       5.63       1.47       4.51
## # … with 20 more rows</code></pre>
<pre class="r"><code># new variables
new_info = tibble(
    student = 1:(2*N),
    score_wpa5 = mean_score_students*0.5 + rnorm(2*N, 0, 1),
    gender = rbinom(2*N, 1, .5)
)

print(new_info)</code></pre>
<pre><code>## # A tibble: 30 x 3
##    student score_wpa5 gender
##      &lt;int&gt;      &lt;dbl&gt;  &lt;int&gt;
##  1       1       3.90      0
##  2       2       3.60      1
##  3       3       5.04      1
##  4       4       3.17      0
##  5       5       3.22      0
##  6       6       1.71      0
##  7       7       5.62      0
##  8       8       4.41      0
##  9       9       4.69      0
## 10      10       4.79      1
## # … with 20 more rows</code></pre>
<pre class="r"><code>fake_data = bind_cols(fake_data,
                      new_info)</code></pre>
<pre><code>## New names:
## * student -&gt; student...1
## * student -&gt; student...7</code></pre>
<pre class="r"><code>print(fake_data)</code></pre>
<pre><code>## # A tibble: 30 x 9
##    student...1   age score_wpa1 score_wpa2 score_wpa3 score_wpa4 student...7 score_wpa5 gender
##          &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;       &lt;int&gt;      &lt;dbl&gt;  &lt;int&gt;
##  1           1    35       8.49       7.89       5.20       6.07           1       3.90      0
##  2           2    28       8.33       7.39       3.52       5.82           2       3.60      1
##  3           3    27       6.65       6.03       6.07       4.49           3       5.04      1
##  4           4    34       9.52       8.54       4.30       7.01           4       3.17      0
##  5           5    35       9.46       8.52       3.87       6.83           5       3.22      0
##  6           6    26       8.76       7.87       4.62       6.29           6       1.71      0
##  7           7    38       6.84       6.25       4.78       4.94           7       5.62      0
##  8           8    33       5.38       4.95       3.66       3.61           8       4.41      0
##  9           9    28       6.81       6.28       3.00       4.85           9       4.69      0
## 10          10    33       6.42       5.63       1.47       4.51          10       4.79      1
## # … with 20 more rows</code></pre>
<p>However, a better way to join dataframes is to use the <code>join</code> functions, as these allow us to join dataframes based on specific ID. This is very important when there are repeating info and/or missing info:</p>
<pre class="r"><code>N = 15
mean_score_students = runif(N, 5, 10)
first_batch = tibble(
    student = 1:N,
    age = round(rnorm(N, 30, 5)),
    score_wpa1 = mean_score_students,
    score_wpa2 = mean_score_students*0.9 + rnorm(N, 0, 0.1),
    score_wpa3 = mean_score_students*0.5 + rnorm(N, 0, 1),
    score_wpa4 = mean_score_students*0.7 + rnorm(N, 0, 0.2)
)
print(first_batch)</code></pre>
<pre><code>## # A tibble: 15 x 6
##    student   age score_wpa1 score_wpa2 score_wpa3 score_wpa4
##      &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1       1    34       8.06       7.18       5.00       5.55
##  2       2    27       6.23       5.62       4.11       4.50
##  3       3    27       7.60       6.87       4.03       5.28
##  4       4    35       5.03       4.73       3.36       3.59
##  5       5    26       7.42       6.76       5.00       5.08
##  6       6    27       5.96       5.37       3.79       4.37
##  7       7    30       5.28       4.63       3.20       3.87
##  8       8    32       5.12       4.59       1.40       3.52
##  9       9    27       7.20       6.40       3.10       5.47
## 10      10    25       9.35       8.46       6.03       6.62
## 11      11    31       8.59       7.80       5.01       6.28
## 12      12    38       9.30       8.37       6.01       6.48
## 13      13    34       6.51       5.87       3.37       4.46
## 14      14    24       9.73       8.98       3.90       6.79
## 15      15    18       8.88       7.87       4.04       5.94</code></pre>
<pre class="r"><code>M = 5
mean_score_students = runif(M, 8, 10)
second_batch = tibble( 
    student = (N+1):(N+M),
    age = round(rnorm(M, 30, 5)),
    score_wpa1 = mean_score_students,
    score_wpa2 = mean_score_students*0.9 + rnorm(M, 0, 0.1),
    score_wpa5 = mean_score_students*0.5 + rnorm(M, 0, 1)
)
print(second_batch)</code></pre>
<pre><code>## # A tibble: 5 x 5
##   student   age score_wpa1 score_wpa2 score_wpa5
##     &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1      16    21       9.34       8.55       4.57
## 2      17    29       8.46       7.71       4.20
## 3      18    37       8.86       8.11       5.15
## 4      19    29       9.69       8.66       3.03
## 5      20    34       8.92       8.03       4.89</code></pre>
<pre class="r"><code>new_info = tibble(
    student = 1:(N+M),
    score_wpa6 = runif(N+M, 6, 10)*0.5 + rnorm(N+M, 0, 1),
    gender = rbinom(N+M, 1, .5)
)
print(new_info)</code></pre>
<pre><code>## # A tibble: 20 x 3
##    student score_wpa6 gender
##      &lt;int&gt;      &lt;dbl&gt;  &lt;int&gt;
##  1       1       4.64      0
##  2       2       5.01      1
##  3       3       4.47      1
##  4       4       1.82      1
##  5       5       4.74      1
##  6       6       4.90      0
##  7       7       5.50      0
##  8       8       3.84      1
##  9       9       3.61      0
## 10      10       1.90      1
## 11      11       2.09      1
## 12      12       3.97      1
## 13      13       3.66      0
## 14      14       4.51      1
## 15      15       1.70      0
## 16      16       4.34      1
## 17      17       3.40      1
## 18      18       3.19      1
## 19      19       3.12      0
## 20      20       5.06      0</code></pre>
<pre class="r"><code>full_join(first_batch, second_batch, by=&#39;student&#39;)</code></pre>
<pre><code>## # A tibble: 20 x 10
##    student age.x score_wpa1.x score_wpa2.x score_wpa3 score_wpa4 age.y score_wpa1.y score_wpa2.y score_wpa5
##      &lt;int&gt; &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
##  1       1    34         8.06         7.18       5.00       5.55    NA        NA           NA         NA   
##  2       2    27         6.23         5.62       4.11       4.50    NA        NA           NA         NA   
##  3       3    27         7.60         6.87       4.03       5.28    NA        NA           NA         NA   
##  4       4    35         5.03         4.73       3.36       3.59    NA        NA           NA         NA   
##  5       5    26         7.42         6.76       5.00       5.08    NA        NA           NA         NA   
##  6       6    27         5.96         5.37       3.79       4.37    NA        NA           NA         NA   
##  7       7    30         5.28         4.63       3.20       3.87    NA        NA           NA         NA   
##  8       8    32         5.12         4.59       1.40       3.52    NA        NA           NA         NA   
##  9       9    27         7.20         6.40       3.10       5.47    NA        NA           NA         NA   
## 10      10    25         9.35         8.46       6.03       6.62    NA        NA           NA         NA   
## 11      11    31         8.59         7.80       5.01       6.28    NA        NA           NA         NA   
## 12      12    38         9.30         8.37       6.01       6.48    NA        NA           NA         NA   
## 13      13    34         6.51         5.87       3.37       4.46    NA        NA           NA         NA   
## 14      14    24         9.73         8.98       3.90       6.79    NA        NA           NA         NA   
## 15      15    18         8.88         7.87       4.04       5.94    NA        NA           NA         NA   
## 16      16    NA        NA           NA         NA         NA       21         9.34         8.55       4.57
## 17      17    NA        NA           NA         NA         NA       29         8.46         7.71       4.20
## 18      18    NA        NA           NA         NA         NA       37         8.86         8.11       5.15
## 19      19    NA        NA           NA         NA         NA       29         9.69         8.66       3.03
## 20      20    NA        NA           NA         NA         NA       34         8.92         8.03       4.89</code></pre>
<pre class="r"><code>full_join(first_batch, second_batch, by=c(&#39;student&#39;, &#39;age&#39;, &quot;score_wpa1&quot;, &quot;score_wpa2&quot;))</code></pre>
<pre><code>## # A tibble: 20 x 7
##    student   age score_wpa1 score_wpa2 score_wpa3 score_wpa4 score_wpa5
##      &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
##  1       1    34       8.06       7.18       5.00       5.55      NA   
##  2       2    27       6.23       5.62       4.11       4.50      NA   
##  3       3    27       7.60       6.87       4.03       5.28      NA   
##  4       4    35       5.03       4.73       3.36       3.59      NA   
##  5       5    26       7.42       6.76       5.00       5.08      NA   
##  6       6    27       5.96       5.37       3.79       4.37      NA   
##  7       7    30       5.28       4.63       3.20       3.87      NA   
##  8       8    32       5.12       4.59       1.40       3.52      NA   
##  9       9    27       7.20       6.40       3.10       5.47      NA   
## 10      10    25       9.35       8.46       6.03       6.62      NA   
## 11      11    31       8.59       7.80       5.01       6.28      NA   
## 12      12    38       9.30       8.37       6.01       6.48      NA   
## 13      13    34       6.51       5.87       3.37       4.46      NA   
## 14      14    24       9.73       8.98       3.90       6.79      NA   
## 15      15    18       8.88       7.87       4.04       5.94      NA   
## 16      16    21       9.34       8.55      NA         NA          4.57
## 17      17    29       8.46       7.71      NA         NA          4.20
## 18      18    37       8.86       8.11      NA         NA          5.15
## 19      19    29       9.69       8.66      NA         NA          3.03
## 20      20    34       8.92       8.03      NA         NA          4.89</code></pre>
<pre class="r"><code>left_join(first_batch, new_info, by=c(&#39;student&#39;))</code></pre>
<pre><code>## # A tibble: 15 x 8
##    student   age score_wpa1 score_wpa2 score_wpa3 score_wpa4 score_wpa6 gender
##      &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;
##  1       1    34       8.06       7.18       5.00       5.55       4.64      0
##  2       2    27       6.23       5.62       4.11       4.50       5.01      1
##  3       3    27       7.60       6.87       4.03       5.28       4.47      1
##  4       4    35       5.03       4.73       3.36       3.59       1.82      1
##  5       5    26       7.42       6.76       5.00       5.08       4.74      1
##  6       6    27       5.96       5.37       3.79       4.37       4.90      0
##  7       7    30       5.28       4.63       3.20       3.87       5.50      0
##  8       8    32       5.12       4.59       1.40       3.52       3.84      1
##  9       9    27       7.20       6.40       3.10       5.47       3.61      0
## 10      10    25       9.35       8.46       6.03       6.62       1.90      1
## 11      11    31       8.59       7.80       5.01       6.28       2.09      1
## 12      12    38       9.30       8.37       6.01       6.48       3.97      1
## 13      13    34       6.51       5.87       3.37       4.46       3.66      0
## 14      14    24       9.73       8.98       3.90       6.79       4.51      1
## 15      15    18       8.88       7.87       4.04       5.94       1.70      0</code></pre>
<pre class="r"><code>right_join(new_info, second_batch, by=c(&#39;student&#39;))</code></pre>
<pre><code>## # A tibble: 5 x 7
##   student score_wpa6 gender   age score_wpa1 score_wpa2 score_wpa5
##     &lt;int&gt;      &lt;dbl&gt;  &lt;int&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1      16       4.34      1    21       9.34       8.55       4.57
## 2      17       3.40      1    29       8.46       7.71       4.20
## 3      18       3.19      1    37       8.86       8.11       5.15
## 4      19       3.12      0    29       9.69       8.66       3.03
## 5      20       5.06      0    34       8.92       8.03       4.89</code></pre>
</div>
<div id="now-its-your-turn" class="section level1">
<h1>6. Now it’s your turn</h1>
<p>Now you will analyze data from Matthews et al. (2016): Why do we overestimate others’ willingness to pay? The purpose of this research was to test if our beliefs about other people’s affluence (i.e.; wealth) affect how much we think they will be willing to pay for items. You can find the full paper at <a href="http://journal.sjdm.org/15/15909/jdm15909.pdf" class="uri">http://journal.sjdm.org/15/15909/jdm15909.pdf</a>.</p>
<p><strong>Variables description:</strong></p>
<p>Here are descriptions of the data variables (taken from the author’s dataset notes available at <a href="http://journal.sjdm.org/15/15909/Notes.txt" class="uri">http://journal.sjdm.org/15/15909/Notes.txt</a>)</p>
<ul>
<li><code>id</code>: participant id code</li>
<li><code>gender</code>: participant gender. 1 = male, 2 = female</li>
<li><code>age</code>: participant age</li>
<li><code>income</code>: participant annual household income on categorical scale with 8 categorical options: Less than 5,000; 15,001–25,000; 25,001–35,000; 35,001–50,000; 50,001–75,000; 75,001–100,000; 100,001–150,000; greater than 150,000.</li>
<li><code>p1-p10</code>: whether the “typical” survey respondent would pay more (coded 1) or less (coded 0) than oneself, for each of the 10 products</li>
<li><code>task</code>: whether the participant had to judge the proportion of other people who “have more money than you do” (coded 1) or the proportion who “have less money than you do” (coded 0)</li>
<li><code>havemore</code>: participant’s response when task = 1</li>
<li><code>haveless</code>: participant’s response when task = 0</li>
<li><code>pcmore</code>: participant’s estimate of the proportion of people who have more than they do (calculated as 100-haveless when task=0)</li>
</ul>
<p><strong>Task A</strong></p>
<p>First, download the <code>data_wpa4.csv</code> and <code>matthews_demographics.csv</code> datasets from the <a href="https://github.com/laurafontanesi/r-seminar22/tree/main/data">data folder on Github</a> and load them in R.</p>
<p>Note: do not use pipes from 1 to 4.</p>
<ol style="list-style-type: decimal">
<li><p>Currently <code>gender</code> is coded as 1 and 2. Create a new dataframe called <code>new_matthews_data</code>, in which there is a new column called <code>gender_labels</code> that codes gender as “male” and “female”. Do it using <code>mutate</code>. Then, rename the original <code>gender</code> column to <code>gender_binary</code> using <code>rename</code>. Subtract 1 to all values of <code>gender_binary</code>, so that it is coded as 0 and 1 instead of 1 and 2 using <code>mutate</code> again.</p></li>
<li><p>In <code>new_matthews_data</code>, create new column called <code>income_labels</code> that codes income based on the data description above using <code>mutate</code>. Then, create a new column, called <code>income_recoded</code>, where you only have 4 income categories (coded as numbers from 1 to 4): below 25,000, 25,000-50,000, 50,000-100,000, and above 100,000 using <code>case_when</code>. How many observations are there for each of these 4 categories? Use <code>summarise</code> to reply.</p></li>
<li><p>In <code>new_matthews_data</code>, transform all numeric columns into integers numbers using <code>mutate_if</code>.</p></li>
<li><p>From <code>new_matthews_data</code>, create a summary of the dataset using <code>summarise</code>, to answer the following questions: What percent of participants were female? What was the minimum, mean, and maximum <code>income</code>? What was the 25th percentile, median, and the 75th percentile of <code>age</code>? Use good names for columns.</p></li>
<li><p>Repeat steps from 1 to 4 (apart from the <code>summarise</code> in point 2) using pipes and assign the result to <code>new_matthews_data_summary</code>.</p></li>
</ol>
<p><strong>Task B</strong></p>
<ol style="list-style-type: decimal">
<li><p>From <code>new_matthews_data</code>, calculate the mean <code>p1</code> to <code>p10</code> across participants using <code>summarise_all</code> and <code>select</code>. Which product scored the highest? Do it again, grouping the data by gender. Is there a difference across gender? What is the mean of the mean <code>p1</code> to <code>p10</code> across participants? Calculate it on the result of the previous step. You can do these either using pipes or not.</p></li>
<li><p>Transform the data from wide to long format. In particular, you want 10 rows per subjects, with their responses on the products 1 to 10 in a column called <code>wtp</code>, and the product label in a column called <code>product</code>. Call the resulting dataframe <code>new_matthews_data_long</code>. Re-order it by <code>id</code>. Print the first 20 cases to check this worked. Check that <code>new_matthews_data_long</code> has 10 times more rows than <code>new_matthews_data</code>.</p></li>
</ol>
<pre><code># these are the solutions for B2, as we will cover wide to long data transformation later in the seminar
new_matthews_data_long = gather(new_matthews_data,
                                key=&#39;product&#39;,
                                value=&#39;wtp&#39;,
                                p1:p10)

new_matthews_data_long = arrange(new_matthews_data_long, id)</code></pre>
<p><strong>Task C</strong></p>
<ol style="list-style-type: decimal">
<li><p>Drop the <code>X1</code> column in <code>demographics</code> using <code>select</code>.</p></li>
<li><p>Join <code>new_matthews_data_long</code> and <code>demographics</code> based on the <code>id</code>, in order to retain as many rows and columns as possible. Call the resulting dataframe <code>matthews_data_all</code>.</p></li>
<li><p>Calculate the mean <code>wtp</code> per subject using <code>group_by</code>. You can use pipes or not. Called the resulting dataframe <code>mean_matthews_data_all</code>. This should have as many rows as the number of subjects and 2 columns (<code>id</code> and mean wtp). Add as a third and fourth columns <code>heigth</code> and <code>race</code> using one of the join functions.</p></li>
<li><p>Using <code>mean_matthews_data_all</code>, make a barplot showing the mean <code>wtp</code> across ethnic groups. Plot confidence intervals. Give appropriate labels to the plot. Do you think there is a difference in willingness to pay across groups?</p></li>
</ol>
<pre><code># these are the solutions for B4, as we will cover plotting later in the seminar
ggplot(data = mean_matthews_data_all, mapping = aes(x = factor(race), y = mean_wtp)) +
    stat_summary(fun = &quot;mean&quot;, geom=&quot;bar&quot;) +
    stat_summary(fun.data = mean_cl_normal, geom = &quot;errorbar&quot;, size=1, width=.4) +
    labs(x = &#39;Race&#39;, y = &#39;Mean WTP&#39;) + 
    theme(axis.text.x = element_text(angle = 90))</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Using <code>mean_matthews_data_all</code>, make a scatterplot showing the wtp on the y-axis and the height on the x-axis. Add a regression line. Do you think height predicts willingness to pay?</li>
</ol>
<pre><code># these are the solutions for B5, as we will cover plotting later in the seminar
ggplot(data = mean_matthews_data_all, mapping = aes(x = height, y = mean_wtp)) + 
    geom_point(alpha = 0.3, size= 2) +
    geom_smooth(method = lm, color=&#39;grey&#39;) +
    labs(x=&#39;Height&#39;, y=&#39;Mean WTP&#39;) +
    ggtitle(&quot;Relationship betweenheight and WTP&quot;)</code></pre>
<div id="submit-your-assignment" class="section level2">
<h2>Submit your assignment</h2>
<p>Save and email your script to me at <a href="mailto:laura.fontanesi@unibas.ch">laura.fontanesi@unibas.ch</a> by the end of Friday.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
